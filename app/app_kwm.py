import os
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import uuid  # â˜… è¿½åŠ ï¼šã‚»ãƒƒã‚·ãƒ§ãƒ³è­˜åˆ¥ç”¨

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# ---------------------------------------------------------
# .env èª­ã¿è¾¼ã¿ & ç’°å¢ƒå¤‰æ•°
# ---------------------------------------------------------
load_dotenv()

LOCALLM_API_KEY = os.getenv("LOCALLM_API_KEY")
LOCALLM_BASE_URL = os.getenv(
    "LOCALLM_BASE_URL",
    "",
)
LOCALLM_CHAT_MODEL = os.getenv("LOCALLM_CHAT_MODEL", "")

# ---------------------------------------------------------
# ãƒ‘ã‚¹è¨­å®š
# app_kwm.py ã¯ app/ é…ä¸‹ã«ã‚ã‚‹æƒ³å®š
# ãƒ«ãƒ¼ãƒˆ:
#   LOCALLMAI_LILT/
#     app/app_kwm.py
#     data/knowledge.txt
#     data/system_prompt.txt
#     data/uploads/
#     logs/
# ---------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parents[1]
DATA_DIR = BASE_DIR / "data"
LOGS_DIR = BASE_DIR / "logs"
LOGS_DIR.mkdir(exist_ok=True)

UPLOAD_DIR = DATA_DIR / "uploads"
UPLOAD_DIR.mkdir(exist_ok=True)


# ---------------------------------------------------------
# ãƒ­ã‚°æ›¸ãè¾¼ã¿ï¼ˆ1è¡Œ1JSON ã® jsonl å½¢å¼ï¼‰
#   âš  æ—¥ä»˜ + ãƒ©ãƒ³ãƒ€ãƒ æ–‡å­—åˆ—ã§ã€Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã€ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
# ---------------------------------------------------------
def log_interaction(
    question: str,
    answer: str,
    contexts: List[str],
    extra: Dict[str, Any] | None = None,
) -> None:
    """logs/ å†…ã® <æ—¥ä»˜>_<ãƒ©ãƒ³ãƒ€ãƒ >.jsonl ã« Q&A ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½è¨˜"""
    extra = extra or {}

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã« 1 ã¤ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒã¤
    log_name = st.session_state.get("log_file_name")
    if not log_name:
        date_str = datetime.now().strftime("%Y%m%d")
        rand = uuid.uuid4().hex[:8]
        log_name = f"{date_str}_{rand}.jsonl"
        st.session_state.log_file_name = log_name

    log_path = LOGS_DIR / log_name

    record: Dict[str, Any] = {
        "timestamp": datetime.now().isoformat(),
        "question": question,
        "answer": answer,
        "contexts": contexts,
    }
    record.update(extra)

    with log_path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")


def list_log_files() -> List[Path]:
    """logs/ é…ä¸‹ã® *.jsonl ã‚’æ–°ã—ã„é †ã«è¿”ã™"""
    files = sorted(LOGS_DIR.glob("*.jsonl"), reverse=True)
    return files


def load_history_from_log(log_path: Path) -> List[Dict[str, str]]:
    """logs/YYYYMMDD_xxxxxxxx.jsonl ã‹ã‚‰ history ã‚’çµ„ã¿ç«‹ã¦ã‚‹"""
    history: List[Dict[str, str]] = []
    if not log_path.exists():
        return history

    with log_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                rec = json.loads(line)
            except json.JSONDecodeError:
                continue
            q = rec.get("question")
            a = rec.get("answer")
            if q and a:
                history.append({"user": q, "assistant": a})
    return history


# ---------------------------------------------------------
# LOCALLM AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
# ---------------------------------------------------------
def get_client():
    """LOCALLM AI ç”¨ OpenAI äº’æ›ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¿”ã™ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ str ã‚’è¿”ã™ï¼‰"""
    if not LOCALLM_API_KEY:
        return "LOCALLM_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

    client = OpenAI(
        api_key=LOCALLM_API_KEY,
        base_url=LOCALLM_BASE_URL,
    )
    return client


# ---------------------------------------------------------
# system_prompt.txt èª­ã¿è¾¼ã¿
# ---------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_system_prompt() -> str:
    """
    data/system_prompt.txt ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€ã€‚
    ç„¡ã„ or ç©ºãªã‚‰ã€å¾“æ¥ã®å›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦è¿”ã™ã€‚
    """
    path = DATA_DIR / "system_prompt.txt"
    if path.exists():
        txt = path.read_text(encoding="utf-8").strip()
        if txt:
            return txt

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆã„ã¾ã¾ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ãŸå†…å®¹ï¼‰
    return (
        "ã‚ãªãŸã¯ã ã‹ã‚‰ã“ãç”Ÿå‘½ä¿é™ºå‘ã‘ã®ç¤¾å†…ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯AIã§ã™ã€‚å¸¸ã«æ—¥æœ¬èªã§ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        "æ¬¡ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ãŒã‚ã‚Œã°ã€ã§ãã‚‹ã ã‘å„ªå…ˆã—ã¦æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚\n"
        "ãƒŠãƒ¬ãƒƒã‚¸ã«ç„¡ã„å†…å®¹ã«ã¤ã„ã¦èã‹ã‚ŒãŸå ´åˆã¯ã€ãã®æ—¨ã‚’ä¼ãˆãŸä¸Šã§ã€"
        "ä¸€èˆ¬è«–ã¨ã—ã¦ç­”ãˆã‚‰ã‚Œã‚‹ç¯„å›²ã§è£œè¶³ã—ã¦ãã ã•ã„ã€‚"
    )


# ---------------------------------------------------------
# ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸èª­ã¿è¾¼ã¿
#   - data/knowledge.txt ï¼ˆç©ºè¡ŒåŒºåˆ‡ã‚Šã§ 1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰
#   - data/uploads/*.txt, *.md ï¼ˆç©ºè¡ŒåŒºåˆ‡ã‚Šã§ 1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰
#   - data/uploads/*.csv ï¼ˆ1 è¡Œ = 1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ‰±ã„ï¼‰
# ---------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_knowledge() -> List[str]:
    docs: List[str] = []

    # 1) data/knowledge.txt
    knowledge_path = DATA_DIR / "knowledge.txt"
    if knowledge_path.exists():
        text = knowledge_path.read_text(encoding="utf-8", errors="ignore")
        docs.extend(b.strip() for b in text.split("\n\n") if b.strip())

    # 2) data/uploads/*.txt, *.md
    for path in UPLOAD_DIR.glob("*.txt"):
        try:
            text = path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            continue
        docs.extend(b.strip() for b in text.split("\n\n") if b.strip())

    # 3) data/uploads/*.csv ï½¥ï½¥ï½¥ 1 è¡Œ = 1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    import csv

    for path in UPLOAD_DIR.glob("*.csv"):
        try:
            with path.open("r", encoding="utf-8", errors="ignore", newline="") as f:
                reader = csv.reader(f)
                header = next(reader, None)  # 1è¡Œç›®ãƒ˜ãƒƒãƒ€ãƒ¼æƒ³å®š
                for row in reader:
                    line = ", ".join(col.strip() for col in row if col.strip())
                    if line:
                        docs.append(line)
        except Exception:
            continue

    return docs


def get_knowledge_docs() -> List[str]:
    """knowledge.txt + uploads å†…ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’è¿”ã™"""
    return load_knowledge()


# ---------------------------------------------------------
# Streamlit ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
# ---------------------------------------------------------
def init_session_state() -> None:
    if "messages" not in st.session_state:
        st.session_state.messages: List[Dict[str, str]] = []

    if "history" not in st.session_state:
        # [{"user": "...", "assistant": "..."}, ...]
        st.session_state.history: List[Dict[str, str]] = []

    if "loaded_log_name" not in st.session_state:
        st.session_state.loaded_log_name: str | None = None

    # â˜… è¿½åŠ ï¼šã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ä½¿ã†ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å
    if "log_file_name" not in st.session_state:
        st.session_state.log_file_name: str | None = None


def add_history(user: str, assistant: str) -> None:
    """ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ & Chat UI ä¸¡æ–¹ã«è¿½åŠ """
    st.session_state.history.append({"user": user, "assistant": assistant})
    st.session_state.messages.append({"role": "user", "content": user})
    st.session_state.messages.append({"role": "assistant", "content": assistant})


def get_history() -> List[Dict[str, str]]:
    return st.session_state.history


# ---------------------------------------------------------
# ã‚·ãƒ³ãƒ—ãƒ«ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
# ---------------------------------------------------------
def tokenize(text: str) -> List[str]:
    """è¶…ç°¡æ˜“ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆç©ºç™½ã¨ä¸€éƒ¨è¨˜å· + æ—¥æœ¬èªã®ãŠæ±ºã¾ã‚Šãƒ•ãƒ¬ãƒ¼ã‚ºã§åˆ†å‰²ï¼‰"""

    # â‘  æ—¥æœ¬èªã‚¯ã‚¨ãƒªã§ã‚ˆãä»˜ã‘ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ã‚ã‚‰ã‹ã˜ã‚ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®ãæ›ãˆã‚‹
    jp_phrases = [
        "ã«ã¤ã„ã¦æ•™ãˆã¦",
        "ã«ã¤ã„ã¦",
        "ã¨ã¯ä½•ã§ã™ã‹",
        "ã¨ã¯ãªã‚“ã§ã™ã‹",
        "ã¨ã¯ï¼Ÿ",
        "ã¨ã¯?",
        "ã¨ã¯",
        "ã£ã¦ä½•",
        "ã£ã¦ãªã«",
        "ã®ã“ã¨ã‚’æ•™ãˆã¦",
        "ã®ã“ã¨æ•™ãˆã¦",
        "ã®ã“ã¨",
        "ã‚’æ•™ãˆã¦",
    ]
    for p in jp_phrases:
        text = text.replace(p, " ")

    # â‘¡ è¨˜å·é¡ã§ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã«ã™ã‚‹ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    seps = " \t\r\nã€ã€‚ãƒ»ï¼Œï¼ã€Œã€ã€ã€()ï¼ˆï¼‰[]ã€ã€‘ï¼š:ï¼›;!?ï¼ï¼Ÿ"
    for ch in seps:
        text = text.replace(ch, " ")

    tokens = [t for t in text.lower().split(" ") if t]

    # â‘¢ è¨˜å·ã ã‘ãƒ»1æ–‡å­—ã™ãã‚‹ã‚‚ã®ã‚’ã–ã£ãã‚Šé™¤å»ï¼ˆè‹±æ•°å­—å‘ã‘ã®ç°¡æ˜“ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
    cleaned = []
    for t in tokens:
        # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é•·ã•1ã§ã‚‚æ®‹ã™
        if any("\u3040" <= ch <= "\u30ff" or "\u4e00" <= ch <= "\u9fff" for ch in t):
            cleaned.append(t)
        else:
            if len(t) >= 2:
                cleaned.append(t)

    return cleaned


def search_knowledge(query: str, docs: List[str], top_k: int = 3) -> List[str]:
    """Jaccard + éƒ¨åˆ†ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹ã§ã‚·ãƒ³ãƒ—ãƒ«ã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""

    if not docs:
        return []

    # è³ªå•å´ã®ãƒˆãƒ¼ã‚¯ãƒ³
    q_tokens = tokenize(query)
    # é•·ã• 1 ã®è¨˜å·ã£ã½ã„ã‚‚ã®ã¯é›‘ã«æ¨ã¦ã‚‹
    q_tokens = [t for t in q_tokens if len(t) >= 2]

    # ãã‚Œã§ã‚‚ä½•ã‚‚æ®‹ã‚‰ãªã‘ã‚Œã°ã€ç”Ÿã®ã‚¯ã‚¨ãƒªã‚’ãã®ã¾ã¾ 1 å€‹ã ã‘ä½¿ã†
    if not q_tokens:
        q_tokens = [query.strip()] if query.strip() else []

    if not q_tokens:
        return []

    scored: List[tuple[float, str]] = []

    for doc in docs:
        doc_text = doc  # æ—¥æœ¬èªãªã®ã§ lower() ã¯ã‚ã¾ã‚Šæ„å‘³ãªã—

        # 1) Jaccard ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚³ã‚¢
        base_score = 0.0
        d_tokens = tokenize(doc)
        if d_tokens:
            q_set = set(q_tokens)
            d_set = set(d_tokens)
            inter = len(q_set & d_set)
            union = len(q_set | d_set)
            if union > 0:
                base_score = inter / union  # 0.0ã€œ1.0

        # 2) éƒ¨åˆ†ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹ï¼ˆã©ã‚Œã‹ 1 ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã‚‚å«ã¾ã‚Œã¦ã„ã‚Œã° 0.5 åŠ ç‚¹ï¼‰
        substr_bonus = 0.0
        for kw in q_tokens:
            if kw and kw in doc_text:
                substr_bonus = 0.5
                break

        score = base_score + substr_bonus

        if score > 0:
            scored.append((score, doc))

    # ã‚¹ã‚³ã‚¢é †ã«ä¸¦ã³æ›¿ãˆ
    scored.sort(key=lambda x: x[0], reverse=True)

    return [doc for _, doc in scored[:top_k]]


# ---------------------------------------------------------
# LLM å‘¼ã³å‡ºã—
# ---------------------------------------------------------
def call_local_llm(query: str, contexts: List[str]) -> str:
    client = get_client()
    if isinstance(client, str):
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¿”ã£ã¦ããŸå ´åˆ
        return client

    history = get_history()

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµåˆ
    if contexts:
        context_text = "\n\n---\n\n".join(contexts)
    else:
        context_text = "ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ï¼ˆknowledge.txtï¼‰ã‹ã‚‰é–¢é€£æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

    # system_prompt.txt ã®å†…å®¹ + ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ã‚’çµåˆ
    base_system_prompt = load_system_prompt()
    system_content = (
        f"{base_system_prompt}\n\n"
        "-----\n"
        "ä»¥ä¸‹ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ï¼ˆknowledge.txt / uploads ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸé–¢é€£æƒ…å ±ï¼‰ã§ã™ã€‚"
        "å¿…è¦ã«å¿œã˜ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"{context_text}"
    )

    messages: List[Dict[str, str]] = [
        {"role": "system", "content": system_content},
    ]

    # ç›´è¿‘ 5 ã‚¿ãƒ¼ãƒ³åˆ†ã®å±¥æ­´ã‚’è¿½åŠ 
    for turn in history[-5:]:
        messages.append({"role": "user", "content": turn["user"]})
        messages.append({"role": "assistant", "content": turn["assistant"]})

    messages.append({"role": "user", "content": query})

    resp = client.chat.completions.create(
        model=LOCALLM_CHAT_MODEL,
        messages=messages,
        temperature=0.3,
    )

    answer = resp.choices[0].message.content or ""
    return answer


# ---------------------------------------------------------
# Streamlit UI
# ---------------------------------------------------------
def main() -> None:
    st.set_page_config(page_title="Keyword match LLM", page_icon="ğŸ’¬", layout="wide")
    st.title("LocallmğŸ’¬")
    st.caption(
        "Locallm - Keyword match LLM - Built with Streamlit, a product of Knock Knock Inc. "
        "For internal, local-only purposes. Not utilized for LLM training datasets or models."
    )
    init_session_state()
    docs = get_knowledge_docs()
    doc_count = len(docs)

    # -----------------------------
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    # -----------------------------
    with st.sidebar:
        # æ–°è¦ãƒãƒ£ãƒƒãƒˆ
        if st.button("æ–°è¦ãƒãƒ£ãƒƒãƒˆ", use_container_width=True):
            st.session_state.history = []
            st.session_state.messages = []
            st.session_state.loaded_log_name = None
            st.session_state.log_file_name = None  # â˜… è¿½åŠ ï¼šæ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ãªã®ã§ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚‚ãƒªã‚»ãƒƒãƒˆ
            st.success("æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")
            st.rerun()

        st.markdown("---")

        # ãƒ­ã‚°å±¥æ­´
        st.subheader("å±¥æ­´")
        log_files = list_log_files()
        if not log_files:
            st.caption("logs ãƒ•ã‚©ãƒ«ãƒ€ã«ã¾ã ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.caption("ç›´è¿‘20 ä»¶")
            for log_path in log_files[:20]:
                label = log_path.stem  # ä¾‹: 20251126_ab12cd34
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(label)
                with col2:
                    if st.button("â†’", key=f"load_log_{label}"):
                        history = load_history_from_log(log_path)
                        st.session_state.history = history
                        # Chat UI ç”¨ messages ã‚’å†æ§‹ç¯‰
                        st.session_state.messages = []
                        for turn in history:
                            st.session_state.messages.append(
                                {"role": "user", "content": turn["user"]}
                            )
                            st.session_state.messages.append(
                                {"role": "assistant", "content": turn["assistant"]}
                            )
                        st.session_state.loaded_log_name = label
                        # â˜… è¿½åŠ ï¼šã“ã®ãƒ­ã‚°ã«è¿½è¨˜ã—ãŸã„å ´åˆã«å‚™ãˆã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚‚ä¿æŒ
                        st.session_state.log_file_name = log_path.name
                        st.success(f"{label} ã®å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                        st.rerun()

        if st.session_state.loaded_log_name:
            st.info(f"èª­ã¿è¾¼ã¿ä¸­ã®ãƒ­ã‚°: {st.session_state.loaded_log_name}")

        st.markdown("---")

        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« UI ã¯ä¸€æ—¦å°å°ä¸­ï¼ˆå°†æ¥ä½¿ã†ãªã‚‰ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤ï¼‰
        # st.subheader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ  Î²")
        # ...

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸æ¦‚è¦
        st.header("ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸")
        st.write(f"knowledge.txt + uploads ã®æ–‡æ›¸æ•°: **{doc_count}** ä»¶")

        knowledge_path = DATA_DIR / "knowledge.txt"
        st.caption("knowledge.txt Path")
        st.code(str(knowledge_path), language="text")
        if knowledge_path.exists() and doc_count > 0:
            st.caption("knowledge.txt ç”±æ¥ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€ä¾‹ï¼ˆå†’é ­100æ–‡å­—ï¼‰")
            st.write(docs[0][:100])

        st.markdown("---")

        system_prompt_path = DATA_DIR / "system_prompt.txt"
        st.caption("system_prompt.txt Path")
        st.code(str(system_prompt_path), language="text")
        if system_prompt_path.exists():
            try:
                sp_text = system_prompt_path.read_text(encoding="utf-8").strip()
                if sp_text:
                    st.caption("system_prompt.txt å†’é ­100æ–‡å­—")
                    st.write(sp_text[:100])
                else:
                    st.caption("system_prompt.txt ã¯ç©ºã§ã™ã€‚")
            except Exception as e:
                st.caption(f"system_prompt.txt ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        else:
            st.caption("system_prompt.txt ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

        st.markdown("---")

        st.subheader("ç’°å¢ƒæƒ…å ±")
        st.write(f"Base URL: `{LOCALLM_BASE_URL}`")
        st.write(f"Model: `{LOCALLM_CHAT_MODEL}`")

    # -----------------------------
    # ã“ã‚Œã¾ã§ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    # -----------------------------
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # -----------------------------
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    # -----------------------------
    query = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæ¥½å¤©ç”Ÿå‘½ã®æ¥­å‹™ãƒ»ç¤¾å†… FAQ ãªã©ï¼‰")

    if query:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.write(query)

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢
        with st.spinner("ãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™..."):
            contexts = search_knowledge(query, docs, top_k=3)

        # LLM å‘¼ã³å‡ºã—
        with st.spinner("å•ã„åˆã‚ã›ä¸­..."):
            answer = call_local_llm(query, contexts)

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå›ç­”è¡¨ç¤º
        with st.chat_message("assistant"):
            st.write(answer)

            # ğŸ” ã“ã“ã§ã€Œä»Šå›å‚ç…§ã—ãŸãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ã€ã®è¡¨ç¤º
            if contexts:
                with st.expander("ä»Šå›å‚ç…§ã—ãŸãƒ­ãƒ¼ã‚«ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ï¼ˆknowledge.txt / uploadsï¼‰"):
                    for i, ctx in enumerate(contexts, start=1):
                        st.markdown(f"**Doc {i}**")
                        st.write(ctx)
            else:
                st.caption("knowledge.txt / uploads ã‹ã‚‰é–¢é€£ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ & ãƒ­ã‚°ä¿å­˜
        add_history(query, answer)
        try:
            log_interaction(query, answer, contexts)
        except Exception:
            # ãƒ­ã‚°å¤±æ•—ã§ã‚¢ãƒ—ãƒªãŒè½ã¡ãªã„ã‚ˆã†ã«
            pass


if __name__ == "__main__":
    main()
